{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install piq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import yaml\n",
    "import random\n",
    "import numpy as np\n",
    "from piq import FID\n",
    "from unet import UNet\n",
    "from ddpm import DDPM\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read yaml file\n",
    "with open('config.yaml') as file:\n",
    "  config = yaml.safe_load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7fb92e2f8130>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Setting reproducibility\n",
    "SEED = config['seed']\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "UNet(\n",
       "  (conv): ResidualConv(\n",
       "    (conv1): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (norm1): GroupNorm(1, 32, eps=1e-05, affine=True)\n",
       "    (activation1): GELU(approximate='none')\n",
       "    (conv2): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (activation2): GroupNorm(1, 64, eps=1e-05, affine=True)\n",
       "  )\n",
       "  (down1): Down(\n",
       "    (maxpool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (resconv): ResidualConv(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (norm1): GroupNorm(1, 64, eps=1e-05, affine=True)\n",
       "      (activation1): GELU(approximate='none')\n",
       "      (conv2): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (activation2): GroupNorm(1, 128, eps=1e-05, affine=True)\n",
       "    )\n",
       "    (time_emb): Sequential(\n",
       "      (0): SiLU()\n",
       "      (1): Linear(in_features=256, out_features=128, bias=True)\n",
       "    )\n",
       "  )\n",
       "  (attn1): SelfAttention(\n",
       "    (mha): MultiheadAttention(\n",
       "      (out_proj): NonDynamicallyQuantizableLinear(in_features=128, out_features=128, bias=True)\n",
       "    )\n",
       "    (ln): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "    (ff_self): Sequential(\n",
       "      (0): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "      (1): Linear(in_features=128, out_features=128, bias=True)\n",
       "      (2): GELU(approximate='none')\n",
       "      (3): Linear(in_features=128, out_features=128, bias=True)\n",
       "    )\n",
       "  )\n",
       "  (down2): Down(\n",
       "    (maxpool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (resconv): ResidualConv(\n",
       "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (norm1): GroupNorm(1, 128, eps=1e-05, affine=True)\n",
       "      (activation1): GELU(approximate='none')\n",
       "      (conv2): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (activation2): GroupNorm(1, 256, eps=1e-05, affine=True)\n",
       "    )\n",
       "    (time_emb): Sequential(\n",
       "      (0): SiLU()\n",
       "      (1): Linear(in_features=256, out_features=256, bias=True)\n",
       "    )\n",
       "  )\n",
       "  (attn2): SelfAttention(\n",
       "    (mha): MultiheadAttention(\n",
       "      (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)\n",
       "    )\n",
       "    (ln): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "    (ff_self): Sequential(\n",
       "      (0): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "      (1): Linear(in_features=256, out_features=256, bias=True)\n",
       "      (2): GELU(approximate='none')\n",
       "      (3): Linear(in_features=256, out_features=256, bias=True)\n",
       "    )\n",
       "  )\n",
       "  (bot1): ResidualConv(\n",
       "    (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (norm1): GroupNorm(1, 256, eps=1e-05, affine=True)\n",
       "    (activation1): GELU(approximate='none')\n",
       "    (conv2): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (activation2): GroupNorm(1, 512, eps=1e-05, affine=True)\n",
       "  )\n",
       "  (bot2): ResidualConv(\n",
       "    (conv1): Conv2d(512, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (norm1): GroupNorm(1, 256, eps=1e-05, affine=True)\n",
       "    (activation1): GELU(approximate='none')\n",
       "    (conv2): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (activation2): GroupNorm(1, 512, eps=1e-05, affine=True)\n",
       "  )\n",
       "  (bot3): ResidualConv(\n",
       "    (conv1): Conv2d(512, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (norm1): GroupNorm(1, 128, eps=1e-05, affine=True)\n",
       "    (activation1): GELU(approximate='none')\n",
       "    (conv2): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (activation2): GroupNorm(1, 256, eps=1e-05, affine=True)\n",
       "  )\n",
       "  (up1): Up(\n",
       "    (upsample): Upsample(scale_factor=2.0, mode='bilinear')\n",
       "    (resconv): ResidualConv(\n",
       "      (conv1): Conv2d(384, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (norm1): GroupNorm(1, 64, eps=1e-05, affine=True)\n",
       "      (activation1): GELU(approximate='none')\n",
       "      (conv2): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (activation2): GroupNorm(1, 128, eps=1e-05, affine=True)\n",
       "    )\n",
       "    (time_emb): Sequential(\n",
       "      (0): SiLU()\n",
       "      (1): Linear(in_features=256, out_features=128, bias=True)\n",
       "    )\n",
       "  )\n",
       "  (attn3): SelfAttention(\n",
       "    (mha): MultiheadAttention(\n",
       "      (out_proj): NonDynamicallyQuantizableLinear(in_features=128, out_features=128, bias=True)\n",
       "    )\n",
       "    (ln): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "    (ff_self): Sequential(\n",
       "      (0): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "      (1): Linear(in_features=128, out_features=128, bias=True)\n",
       "      (2): GELU(approximate='none')\n",
       "      (3): Linear(in_features=128, out_features=128, bias=True)\n",
       "    )\n",
       "  )\n",
       "  (up2): Up(\n",
       "    (upsample): Upsample(scale_factor=2.0, mode='bilinear')\n",
       "    (resconv): ResidualConv(\n",
       "      (conv1): Conv2d(192, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (norm1): GroupNorm(1, 32, eps=1e-05, affine=True)\n",
       "      (activation1): GELU(approximate='none')\n",
       "      (conv2): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (activation2): GroupNorm(1, 64, eps=1e-05, affine=True)\n",
       "    )\n",
       "    (time_emb): Sequential(\n",
       "      (0): SiLU()\n",
       "      (1): Linear(in_features=256, out_features=64, bias=True)\n",
       "    )\n",
       "  )\n",
       "  (attn4): SelfAttention(\n",
       "    (mha): MultiheadAttention(\n",
       "      (out_proj): NonDynamicallyQuantizableLinear(in_features=64, out_features=64, bias=True)\n",
       "    )\n",
       "    (ln): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "    (ff_self): Sequential(\n",
       "      (0): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "      (1): Linear(in_features=64, out_features=64, bias=True)\n",
       "      (2): GELU(approximate='none')\n",
       "      (3): Linear(in_features=64, out_features=64, bias=True)\n",
       "    )\n",
       "  )\n",
       "  (out_conv): Conv2d(64, 3, kernel_size=(1, 1), stride=(1, 1))\n",
       ")"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = UNet(in_ch=config['in_ch'], \n",
    "             out_ch=config['out_ch'], \n",
    "             time_dim=config['time_dim'],\n",
    "             device=device)\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PATH = '/home/woody/iwso/iwso089h/diffusion/checkpoints/unet.pth'\n",
    "model.load_state_dict(torch.load(PATH))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "ddpm = DDPM(beta_start=config['beta_start'], \n",
    "            beta_end=config['beta_end'], \n",
    "            steps=config['steps'], \n",
    "            color_channels=config['color_channels'], \n",
    "            image_size=config['image_size'], \n",
    "            device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Batch No: 1\n",
      "Generated Batch No: 2\n",
      "Generated Batch No: 3\n",
      "Generated Batch No: 4\n",
      "Generated Batch No: 5\n",
      "Generated Batch No: 6\n",
      "Generated Batch No: 7\n",
      "Generated Batch No: 8\n",
      "Generated Batch No: 9\n",
      "Generated Batch No: 10\n",
      "Generated Batch No: 11\n",
      "Generated Batch No: 12\n",
      "Generated Batch No: 13\n",
      "Generated Batch No: 14\n",
      "Generated Batch No: 15\n",
      "Generated Batch No: 16\n",
      "Generated Batch No: 17\n",
      "Generated Batch No: 18\n",
      "Generated Batch No: 19\n",
      "Generated Batch No: 20\n",
      "Generated Batch No: 21\n",
      "Generated Batch No: 22\n",
      "Generated Batch No: 23\n",
      "Generated Batch No: 24\n",
      "Generated Batch No: 25\n",
      "Generated Batch No: 26\n",
      "Generated Batch No: 27\n",
      "Generated Batch No: 28\n",
      "Generated Batch No: 29\n",
      "Generated Batch No: 30\n",
      "Generated Batch No: 31\n",
      "Generated Batch No: 32\n",
      "Generated Batch No: 33\n",
      "Generated Batch No: 34\n",
      "Generated Batch No: 35\n",
      "Generated Batch No: 36\n",
      "Generated Batch No: 37\n",
      "Generated Batch No: 38\n",
      "Generated Batch No: 39\n",
      "Generated Batch No: 40\n",
      "Generated Batch No: 41\n",
      "Generated Batch No: 42\n",
      "Generated Batch No: 43\n",
      "Generated Batch No: 44\n",
      "Generated Batch No: 45\n",
      "Generated Batch No: 46\n",
      "Generated Batch No: 47\n",
      "Generated Batch No: 48\n",
      "Generated Batch No: 49\n",
      "Generated Batch No: 50\n",
      "Generated Batch No: 51\n",
      "Generated Batch No: 52\n",
      "Generated Batch No: 53\n",
      "Generated Batch No: 54\n",
      "Generated Batch No: 55\n",
      "Generated Batch No: 56\n",
      "Generated Batch No: 57\n",
      "Generated Batch No: 58\n",
      "Generated Batch No: 59\n",
      "Generated Batch No: 60\n",
      "Generated Batch No: 61\n",
      "Generated Batch No: 62\n",
      "Generated Batch No: 63\n",
      "Generated Batch No: 64\n",
      "Generated Batch No: 65\n",
      "Generated Batch No: 66\n",
      "Generated Batch No: 67\n",
      "Generated Batch No: 68\n",
      "Generated Batch No: 69\n",
      "Generated Batch No: 70\n",
      "Generated Batch No: 71\n",
      "Generated Batch No: 72\n",
      "Generated Batch No: 73\n",
      "Generated Batch No: 74\n",
      "Generated Batch No: 75\n",
      "Generated Batch No: 76\n",
      "Generated Batch No: 77\n",
      "Generated Batch No: 78\n",
      "Generated Batch No: 79\n",
      "Generated Batch No: 80\n"
     ]
    }
   ],
   "source": [
    "batch_size = 256\n",
    "sampled_images = torch.zeros((4096*5, 3, 16, 16)).to(device)\n",
    "\n",
    "for i in range(16*5):\n",
    "    sampled_images[i*batch_size:(i+1)*batch_size] = ddpm.backward_diffusion(model, batch_size)\n",
    "    print(f'Generated Batch No: {i+1}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([89400, 3, 16, 16])"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sprites = torch.tensor(np.load('sprites_1788_16x16.npy')).to(device)\n",
    "sprites = sprites.permute(0, 3, 2, 1)/255.\n",
    "sprites.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1., device='cuda:0')"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sprites.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([20480])"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_indices = torch.randint(low=0, high=sprites.shape[0], size=(sampled_images.shape[0],))\n",
    "random_indices.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([20480, 3, 16, 16])"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sampled_sprites = sprites[random_indices]\n",
    "sampled_sprites.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(38.6496, device='cuda:0', dtype=torch.float64)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fid = FID()\n",
    "fid(sampled_images.reshape(4096*5, 16*16*3), sampled_sprites.reshape(4096*5, 16*16*3))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
